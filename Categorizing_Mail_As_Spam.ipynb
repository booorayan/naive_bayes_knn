{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Categorizing Mail As Spam",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/booorayan/naive_bayes_knn/blob/master/Categorizing_Mail_As_Spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO6d_FsbLS0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckg666OIOIsE",
        "colab_type": "text"
      },
      "source": [
        "# Classifying Mail As Spam or Not "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA6yHyAiOY-v",
        "colab_type": "text"
      },
      "source": [
        "## Defining the Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DJwHd_OLltO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wol-J8YOgao",
        "colab_type": "text"
      },
      "source": [
        "## Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnHvCDtSOku7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuzdtOvlS5oZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# enabling mulitple display in the same cell\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y2YUdeyQqlQ",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwFc4TZ5Qvj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "11b66644-eeda-41b6-c2cf-7a3a4bd2939e"
      },
      "source": [
        "spam = pd.read_csv('spambase.csv', names=range(1,59))\n",
        "spam.head()"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     1     2     3    4     5     6   ...     53     54     55   56    57  58\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.000  0.000  3.756   61   278   1\n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.180  0.048  5.114  101  1028   1\n",
              "2  0.06  0.00  0.71  0.0  1.23  0.19  ...  0.184  0.010  9.821  485  2259   1\n",
              "3  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191   1\n",
              "4  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191   1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf7gtdeBa5O7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "66db09b2-7605-4a51-d4d9-cba8253ddc50"
      },
      "source": [
        "# previewing the first five observations in the dataset\n",
        "print('\\033[1m  First Five Observations:\\033[0m \\n')\n",
        "spam.head()\n",
        "\n",
        "# previewing the last five observations \n",
        "print('\\n\\n\\n\\033[1m  Last Five Observations:\\033[0m \\n' )\n",
        "spam.tail()"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m  First Five Observations:\u001b[0m \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     1     2     3    4     5     6   ...     53     54     55   56    57  58\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.000  0.000  3.756   61   278   1\n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.180  0.048  5.114  101  1028   1\n",
              "2  0.06  0.00  0.71  0.0  1.23  0.19  ...  0.184  0.010  9.821  485  2259   1\n",
              "3  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191   1\n",
              "4  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191   1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 361
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\u001b[1m  Last Five Observations:\u001b[0m \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        1    2     3    4     5     6   ...   53   54     55  56   57  58\n",
              "4596  0.31  0.0  0.62  0.0  0.00  0.31  ...  0.0  0.0  1.142   3   88   0\n",
              "4597  0.00  0.0  0.00  0.0  0.00  0.00  ...  0.0  0.0  1.555   4   14   0\n",
              "4598  0.30  0.0  0.30  0.0  0.00  0.00  ...  0.0  0.0  1.404   6  118   0\n",
              "4599  0.96  0.0  0.00  0.0  0.32  0.00  ...  0.0  0.0  1.147   5   78   0\n",
              "4600  0.00  0.0  0.65  0.0  0.00  0.00  ...  0.0  0.0  1.250   5   40   0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh6gG8wNbtTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "276456d2-5edc-4340-be2a-ba22c43f729f"
      },
      "source": [
        "# checking the number of rows and columns and total no. of observations in the dataframe\n",
        "print('No. of rows:', spam.shape[0])\n",
        "print('No. of columns:', spam.shape[1])\n",
        "print('Total no. of observations:', spam.size)"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of rows: 4601\n",
            "No. of columns: 58\n",
            "Total no. of observations: 266858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKugjDphb9CJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e7c3840-3198-4b2f-d140-ca0ac4bbb524"
      },
      "source": [
        "# checking if the columns have the correct datatypes\n",
        "spam.dtypes"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     float64\n",
              "2     float64\n",
              "3     float64\n",
              "4     float64\n",
              "5     float64\n",
              "6     float64\n",
              "7     float64\n",
              "8     float64\n",
              "9     float64\n",
              "10    float64\n",
              "11    float64\n",
              "12    float64\n",
              "13    float64\n",
              "14    float64\n",
              "15    float64\n",
              "16    float64\n",
              "17    float64\n",
              "18    float64\n",
              "19    float64\n",
              "20    float64\n",
              "21    float64\n",
              "22    float64\n",
              "23    float64\n",
              "24    float64\n",
              "25    float64\n",
              "26    float64\n",
              "27    float64\n",
              "28    float64\n",
              "29    float64\n",
              "30    float64\n",
              "31    float64\n",
              "32    float64\n",
              "33    float64\n",
              "34    float64\n",
              "35    float64\n",
              "36    float64\n",
              "37    float64\n",
              "38    float64\n",
              "39    float64\n",
              "40    float64\n",
              "41    float64\n",
              "42    float64\n",
              "43    float64\n",
              "44    float64\n",
              "45    float64\n",
              "46    float64\n",
              "47    float64\n",
              "48    float64\n",
              "49    float64\n",
              "50    float64\n",
              "51    float64\n",
              "52    float64\n",
              "53    float64\n",
              "54    float64\n",
              "55    float64\n",
              "56      int64\n",
              "57      int64\n",
              "58      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6aVFbrPcDi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35bd92ec-8ad5-49dc-ffcf-2bbd8c085943"
      },
      "source": [
        "# checking the no. of non-null values in the datframe\n",
        "spam.info()"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4601 entries, 0 to 4600\n",
            "Data columns (total 58 columns):\n",
            "1     4601 non-null float64\n",
            "2     4601 non-null float64\n",
            "3     4601 non-null float64\n",
            "4     4601 non-null float64\n",
            "5     4601 non-null float64\n",
            "6     4601 non-null float64\n",
            "7     4601 non-null float64\n",
            "8     4601 non-null float64\n",
            "9     4601 non-null float64\n",
            "10    4601 non-null float64\n",
            "11    4601 non-null float64\n",
            "12    4601 non-null float64\n",
            "13    4601 non-null float64\n",
            "14    4601 non-null float64\n",
            "15    4601 non-null float64\n",
            "16    4601 non-null float64\n",
            "17    4601 non-null float64\n",
            "18    4601 non-null float64\n",
            "19    4601 non-null float64\n",
            "20    4601 non-null float64\n",
            "21    4601 non-null float64\n",
            "22    4601 non-null float64\n",
            "23    4601 non-null float64\n",
            "24    4601 non-null float64\n",
            "25    4601 non-null float64\n",
            "26    4601 non-null float64\n",
            "27    4601 non-null float64\n",
            "28    4601 non-null float64\n",
            "29    4601 non-null float64\n",
            "30    4601 non-null float64\n",
            "31    4601 non-null float64\n",
            "32    4601 non-null float64\n",
            "33    4601 non-null float64\n",
            "34    4601 non-null float64\n",
            "35    4601 non-null float64\n",
            "36    4601 non-null float64\n",
            "37    4601 non-null float64\n",
            "38    4601 non-null float64\n",
            "39    4601 non-null float64\n",
            "40    4601 non-null float64\n",
            "41    4601 non-null float64\n",
            "42    4601 non-null float64\n",
            "43    4601 non-null float64\n",
            "44    4601 non-null float64\n",
            "45    4601 non-null float64\n",
            "46    4601 non-null float64\n",
            "47    4601 non-null float64\n",
            "48    4601 non-null float64\n",
            "49    4601 non-null float64\n",
            "50    4601 non-null float64\n",
            "51    4601 non-null float64\n",
            "52    4601 non-null float64\n",
            "53    4601 non-null float64\n",
            "54    4601 non-null float64\n",
            "55    4601 non-null float64\n",
            "56    4601 non-null int64\n",
            "57    4601 non-null int64\n",
            "58    4601 non-null int64\n",
            "dtypes: float64(55), int64(3)\n",
            "memory usage: 2.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkLd8GFkcTC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn7zQ4cWQwjs",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv8GAY6FV5n-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "941ac502-7fdf-4390-bc52-918d69b1672d"
      },
      "source": [
        "# printing the descriptive statistics of the dataset\n",
        "spam.describe()"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.104553</td>\n",
              "      <td>0.213015</td>\n",
              "      <td>0.280656</td>\n",
              "      <td>0.065425</td>\n",
              "      <td>0.312223</td>\n",
              "      <td>0.095901</td>\n",
              "      <td>0.114208</td>\n",
              "      <td>0.105295</td>\n",
              "      <td>0.090067</td>\n",
              "      <td>0.239413</td>\n",
              "      <td>0.059824</td>\n",
              "      <td>0.541702</td>\n",
              "      <td>0.093930</td>\n",
              "      <td>0.058626</td>\n",
              "      <td>0.049205</td>\n",
              "      <td>0.248848</td>\n",
              "      <td>0.142586</td>\n",
              "      <td>0.184745</td>\n",
              "      <td>1.662100</td>\n",
              "      <td>0.085577</td>\n",
              "      <td>0.809761</td>\n",
              "      <td>0.121202</td>\n",
              "      <td>0.101645</td>\n",
              "      <td>0.094269</td>\n",
              "      <td>0.549504</td>\n",
              "      <td>0.265384</td>\n",
              "      <td>0.767305</td>\n",
              "      <td>0.124845</td>\n",
              "      <td>0.098915</td>\n",
              "      <td>0.102852</td>\n",
              "      <td>0.064753</td>\n",
              "      <td>0.047048</td>\n",
              "      <td>0.097229</td>\n",
              "      <td>0.047835</td>\n",
              "      <td>0.105412</td>\n",
              "      <td>0.097477</td>\n",
              "      <td>0.136953</td>\n",
              "      <td>0.013201</td>\n",
              "      <td>0.078629</td>\n",
              "      <td>0.064834</td>\n",
              "      <td>0.043667</td>\n",
              "      <td>0.132339</td>\n",
              "      <td>0.046099</td>\n",
              "      <td>0.079196</td>\n",
              "      <td>0.301224</td>\n",
              "      <td>0.179824</td>\n",
              "      <td>0.005444</td>\n",
              "      <td>0.031869</td>\n",
              "      <td>0.038575</td>\n",
              "      <td>0.139030</td>\n",
              "      <td>0.016976</td>\n",
              "      <td>0.269071</td>\n",
              "      <td>0.075811</td>\n",
              "      <td>0.044238</td>\n",
              "      <td>5.191515</td>\n",
              "      <td>52.172789</td>\n",
              "      <td>283.289285</td>\n",
              "      <td>0.394045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.305358</td>\n",
              "      <td>1.290575</td>\n",
              "      <td>0.504143</td>\n",
              "      <td>1.395151</td>\n",
              "      <td>0.672513</td>\n",
              "      <td>0.273824</td>\n",
              "      <td>0.391441</td>\n",
              "      <td>0.401071</td>\n",
              "      <td>0.278616</td>\n",
              "      <td>0.644755</td>\n",
              "      <td>0.201545</td>\n",
              "      <td>0.861698</td>\n",
              "      <td>0.301036</td>\n",
              "      <td>0.335184</td>\n",
              "      <td>0.258843</td>\n",
              "      <td>0.825792</td>\n",
              "      <td>0.444055</td>\n",
              "      <td>0.531122</td>\n",
              "      <td>1.775481</td>\n",
              "      <td>0.509767</td>\n",
              "      <td>1.200810</td>\n",
              "      <td>1.025756</td>\n",
              "      <td>0.350286</td>\n",
              "      <td>0.442636</td>\n",
              "      <td>1.671349</td>\n",
              "      <td>0.886955</td>\n",
              "      <td>3.367292</td>\n",
              "      <td>0.538576</td>\n",
              "      <td>0.593327</td>\n",
              "      <td>0.456682</td>\n",
              "      <td>0.403393</td>\n",
              "      <td>0.328559</td>\n",
              "      <td>0.555907</td>\n",
              "      <td>0.329445</td>\n",
              "      <td>0.532260</td>\n",
              "      <td>0.402623</td>\n",
              "      <td>0.423451</td>\n",
              "      <td>0.220651</td>\n",
              "      <td>0.434672</td>\n",
              "      <td>0.349916</td>\n",
              "      <td>0.361205</td>\n",
              "      <td>0.766819</td>\n",
              "      <td>0.223812</td>\n",
              "      <td>0.621976</td>\n",
              "      <td>1.011687</td>\n",
              "      <td>0.911119</td>\n",
              "      <td>0.076274</td>\n",
              "      <td>0.285735</td>\n",
              "      <td>0.243471</td>\n",
              "      <td>0.270355</td>\n",
              "      <td>0.109394</td>\n",
              "      <td>0.815672</td>\n",
              "      <td>0.245882</td>\n",
              "      <td>0.429342</td>\n",
              "      <td>31.729449</td>\n",
              "      <td>194.891310</td>\n",
              "      <td>606.347851</td>\n",
              "      <td>0.488698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.588000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.310000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.276000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.640000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.706000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.540000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>42.810000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>7.270000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>5.260000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>2.610000</td>\n",
              "      <td>9.670000</td>\n",
              "      <td>5.550000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.410000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.140000</td>\n",
              "      <td>9.090000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>5.450000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>20.830000</td>\n",
              "      <td>16.660000</td>\n",
              "      <td>33.330000</td>\n",
              "      <td>9.090000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.690000</td>\n",
              "      <td>6.890000</td>\n",
              "      <td>8.330000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>4.760000</td>\n",
              "      <td>7.140000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>3.570000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.420000</td>\n",
              "      <td>22.050000</td>\n",
              "      <td>2.170000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.385000</td>\n",
              "      <td>9.752000</td>\n",
              "      <td>4.081000</td>\n",
              "      <td>32.478000</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.829000</td>\n",
              "      <td>1102.500000</td>\n",
              "      <td>9989.000000</td>\n",
              "      <td>15841.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                1            2   ...            57           58\n",
              "count  4601.000000  4601.000000  ...   4601.000000  4601.000000\n",
              "mean      0.104553     0.213015  ...    283.289285     0.394045\n",
              "std       0.305358     1.290575  ...    606.347851     0.488698\n",
              "min       0.000000     0.000000  ...      1.000000     0.000000\n",
              "25%       0.000000     0.000000  ...     35.000000     0.000000\n",
              "50%       0.000000     0.000000  ...     95.000000     0.000000\n",
              "75%       0.000000     0.000000  ...    266.000000     1.000000\n",
              "max       4.540000    14.280000  ...  15841.000000     1.000000\n",
              "\n",
              "[8 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adErz4jdiEd9",
        "colab_type": "text"
      },
      "source": [
        "most of the features have similar minimum values but differing maximum values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4D3jjs6Q49C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "ddcef7e1-a24a-40a0-80df-9e2b90fbd70d"
      },
      "source": [
        "# mapl = {0: 'Not Spam', 1: 'Spam'}\n",
        "sns.countplot(x=58, data=spam)\n",
        "plt.xticks(spam[58].unique(), labels=['Spam', 'Non Spam'])\n",
        "plt.title('Countplot Showing Number of Spam and Non Spam Mails', fontsize=16, color='indianred')\n",
        "plt.show();"
      ],
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAEYCAYAAAAZGCxpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "310RyZQLqpKO",
        "colab_type": "text"
      },
      "source": [
        "There is a slight imbalance in the data; there are more non spam emails than spam emails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSyHR74O5mGY",
        "colab_type": "text"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLkEhKXs5rCu",
        "colab_type": "text"
      },
      "source": [
        "According to the description of the dataset, the first 48 columns have information on the percentage of the word count. These columns will serve as the features for our model.\n",
        "\n",
        "The last column will be the target variable as it describes whether an email is spam or not.\n",
        "\n",
        "In the target column, 0 indicates not spam and 1 indicates email is spam)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j22lmTBD5o5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "2c568a01-1bcb-49aa-a02e-afcf73c69014"
      },
      "source": [
        "# specifying our features and target variable\n",
        "features = spam.iloc[:,:48]\n",
        "target = spam.iloc[:,-1]\n",
        "\n",
        "\n",
        "# splitting the features and target variables into training and test sets with a test size of 0.2/20% of dataframe\n",
        "feat_train, feat_test, targ_train, targ_test = train_test_split(features, target, test_size=0.2, random_state=30)\n",
        "\n",
        "print('feat train shape:', feat_train.shape)\n",
        "print('targ train shape:', targ_train.shape)\n",
        "print('feat test shape:', feat_test.shape)\n",
        "print('targ test shape:', targ_test.shape)"
      ],
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feat train shape: (3680, 48)\n",
            "targ train shape: (3680,)\n",
            "feat test shape: (921, 48)\n",
            "targ test shape: (921,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgZnu9tvWObN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKd7xq-l8G3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "fdb37989-8409-4e73-d732-d2d8768dcdff"
      },
      "source": [
        "features.head()"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     1     2     3    4     5     6   ...    43   44    45    46   47   48\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.00  0.0  0.00  0.00  0.0  0.0\n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.00  0.0  0.00  0.00  0.0  0.0\n",
              "2  0.06  0.00  0.71  0.0  1.23  0.19  ...  0.12  0.0  0.06  0.06  0.0  0.0\n",
              "3  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.00  0.0  0.00  0.00  0.0  0.0\n",
              "4  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.00  0.0  0.00  0.00  0.0  0.0\n",
              "\n",
              "[5 rows x 48 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGGumWIDWQ58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mmscaler = MinMaxScaler()\n",
        "feat_train = mmscaler.fit_transform(feat_train)\n",
        "feat_test = mmscaler.transform(feat_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNO_aVBe8PeT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "fb45d68a-6b13-427a-f31a-d5c12491bec9"
      },
      "source": [
        "gauss = GaussianNB()\n",
        "gm = gauss.fit(feat_train, targ_train)\n",
        "\n",
        "g_pred = gm.predict(feat_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(targ_test, g_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(targ_test, g_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(targ_test, g_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 370
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[408 170]\n",
            " [ 13 330]]\n",
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.71      0.82       578\n",
            "           1       0.66      0.96      0.78       343\n",
            "\n",
            "    accuracy                           0.80       921\n",
            "   macro avg       0.81      0.83      0.80       921\n",
            "weighted avg       0.85      0.80      0.80       921\n",
            "\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI2270ZYK3-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "0d682ead-3019-4efb-e4d1-149d5786e1a1"
      },
      "source": [
        "\n",
        "# using the multinomial model to make predictions\n",
        "mult = MultinomialNB()\n",
        "\n",
        "# training the multinomial model with data\n",
        "mult.fit(feat_train, targ_train)\n",
        "\n",
        "mlt_pred = mult.predict(feat_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(targ_test, mlt_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(targ_test, mlt_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(targ_test, mlt_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 371
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87.62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 371
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91       578\n",
            "           1       0.90      0.75      0.82       343\n",
            "\n",
            "    accuracy                           0.88       921\n",
            "   macro avg       0.88      0.85      0.86       921\n",
            "weighted avg       0.88      0.88      0.87       921\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[549  29]\n",
            " [ 85 258]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucf6kxc_HV5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGcjMfSY6_-1",
        "colab_type": "text"
      },
      "source": [
        "### Optimizing Model By Removing Highly Correlated Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmR791Jw-nZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c94fed79-886b-4b33-87c4-178410fe73bf"
      },
      "source": [
        "# Create correlation matrix\n",
        "corr_matrix = features.corr().abs()\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "\n",
        "# Find index of feature columns with correlation greater than 0.95\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
        "to_drop"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFkeN_re-9xd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "63ff6d8f-370c-40ab-9eb8-146e1ab86f0e"
      },
      "source": [
        "# Dropping features that show high correlation \n",
        "spam_cl = features.drop(features[to_drop], axis=1)\n",
        "spam_cl.head()"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     1     2     3    4     5     6   ...    43   44    45    46   47   48\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.00  0.0  0.00  0.00  0.0  0.0\n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.00  0.0  0.00  0.00  0.0  0.0\n",
              "2  0.06  0.00  0.71  0.0  1.23  0.19  ...  0.12  0.0  0.06  0.06  0.0  0.0\n",
              "3  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.00  0.0  0.00  0.00  0.0  0.0\n",
              "4  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.00  0.0  0.00  0.00  0.0  0.0\n",
              "\n",
              "[5 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAdw9NaqLOR0",
        "colab_type": "text"
      },
      "source": [
        "Column 34 was dropped as it had a high correlation with a different column in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS3Ii6odG_XQ",
        "colab_type": "text"
      },
      "source": [
        "### Model Performance with Test Size = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tCBxW5x_mWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "c5e79c4c-9868-4268-fa1a-9f67f98a2e73"
      },
      "source": [
        "# specifying our features and target variable\n",
        "feat = spam_cl.iloc[:,:47]\n",
        "targ = spam.iloc[:,57]\n",
        "\n",
        "\n",
        "# splitting the features and target variables into training and test sets with a test size of 0.2/20% of dataframe\n",
        "featt_train, featt_test, targg_train, targg_test = train_test_split(feat, targ, test_size=0.2, random_state=30)\n",
        "\n",
        "print('featt train shape:', featt_train.shape)\n",
        "print('targg train shape:', targg_train.shape)\n",
        "print('featt test shape:', featt_test.shape)\n",
        "print('targg test shape:', targg_test.shape)\n",
        "# feat.head()"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "featt train shape: (3680, 47)\n",
            "targg train shape: (3680,)\n",
            "featt test shape: (921, 47)\n",
            "targg test shape: (921,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xa5L4YjXx5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mamscaler = MinMaxScaler()\n",
        "featt_train = mamscaler.fit_transform(featt_train)\n",
        "featt_test = mamscaler.transform(featt_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETt9Odws_-yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "e27ad732-9530-4dda-b032-73d5822d1fe4"
      },
      "source": [
        "# instantiating the gaussianNB classifier\n",
        "gaussian = GaussianNB()\n",
        "\n",
        "# fitting the gaussian model with training data\n",
        "gaussian.fit(featt_train, targg_train)\n",
        "\n",
        "# making predictions with model\n",
        "gn_pred = gaussian.predict(featt_test)\n",
        "print('\\n' + '===='*20)\n",
        "\n",
        "# rounding off accuracy score of test set to two decimal places\n",
        "np.round(metrics.accuracy_score(targg_test, gn_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(targg_test, gn_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(targg_test, gn_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 376
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 376
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.71      0.82       578\n",
            "           1       0.67      0.96      0.79       343\n",
            "\n",
            "    accuracy                           0.81       921\n",
            "   macro avg       0.82      0.84      0.81       921\n",
            "weighted avg       0.86      0.81      0.81       921\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[413 165]\n",
            " [ 13 330]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFgzMH-4Jgjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-qMMZ3iJpUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "46f2a23c-2eae-4278-f76e-dac884ffb271"
      },
      "source": [
        "# using the multinomial model to make predictions\n",
        "multinm = MultinomialNB()\n",
        "\n",
        "# training the multinomial model with data\n",
        "multinm.fit(featt_train, targg_train)\n",
        "\n",
        "mnm_pred = multinm.predict(featt_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(targg_test, mnm_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(targg_test, mnm_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(targg_test, mnm_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 377
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87.4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 377
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90       578\n",
            "           1       0.90      0.75      0.82       343\n",
            "\n",
            "    accuracy                           0.87       921\n",
            "   macro avg       0.88      0.85      0.86       921\n",
            "weighted avg       0.88      0.87      0.87       921\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[549  29]\n",
            " [ 87 256]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxLQztDsG43x",
        "colab_type": "text"
      },
      "source": [
        "### Model Performance with Test Size = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxMUcuLY98yV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "b84eedf7-1377-4e41-89f4-7ed0888cb2c8"
      },
      "source": [
        "# specifying our features and target variable\n",
        "ffeat = spam_cl.iloc[:,:47]\n",
        "ttarg = spam.iloc[:,57]\n",
        "\n",
        "\n",
        "# splitting the features and target variables into training and test sets with a test size of 0.3/30% of dataframe\n",
        "ffeatt_train, ffeatt_test, ttargg_train, ttargg_test = train_test_split(ffeat, ttarg, test_size=0.3, random_state=30)\n",
        "\n",
        "print('featt train shape:', ffeatt_train.shape)\n",
        "print('targg train shape:', targg_train.shape)\n",
        "print('featt test shape:', ffeatt_test.shape)\n",
        "print('targg test shape:', ttargg_test.shape)\n",
        "# feat.head()"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "featt train shape: (3220, 47)\n",
            "targg train shape: (3680,)\n",
            "featt test shape: (1381, 47)\n",
            "targg test shape: (1381,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzuhRcBvYNPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minscaler = MinMaxScaler()\n",
        "ffeatt_train = minscaler.fit_transform(ffeatt_train)\n",
        "ffeatt_test = minscaler.transform(ffeatt_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEyCXjfb-TcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "9d20280e-1ae3-4d50-bd22-a295445d8489"
      },
      "source": [
        "gssian = GaussianNB()\n",
        "\n",
        "gssian.fit(ffeatt_train, ttargg_train)\n",
        "\n",
        "gasn_pred = gssian.predict(ffeatt_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(ttargg_test, gasn_pred) * 100, 2) \n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(ttargg_test, gasn_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(ttargg_test, gasn_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 380
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78.93"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 380
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.69      0.80       863\n",
            "           1       0.65      0.95      0.77       518\n",
            "\n",
            "    accuracy                           0.79      1381\n",
            "   macro avg       0.81      0.82      0.79      1381\n",
            "weighted avg       0.84      0.79      0.79      1381\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[596 267]\n",
            " [ 24 494]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0lH5fTF-8pX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "93b4d292-b223-41f4-e41e-ed389b42be87"
      },
      "source": [
        "# using the multinomial model to make predictions\n",
        "multinomi = MultinomialNB()\n",
        "\n",
        "# training the multinomial model with data\n",
        "multinomi.fit(ffeatt_train, ttargg_train)\n",
        "\n",
        "munom_pred = multinomi.predict(ffeatt_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(ttargg_test, munom_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(ttargg_test, munom_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(ttargg_test, munom_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       863\n",
            "           1       0.90      0.78      0.84       518\n",
            "\n",
            "    accuracy                           0.88      1381\n",
            "   macro avg       0.89      0.86      0.87      1381\n",
            "weighted avg       0.89      0.88      0.88      1381\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[819  44]\n",
            " [115 403]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KRl9P8m_Ws2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMh7b5DAGtdP",
        "colab_type": "text"
      },
      "source": [
        "### Model Performance with Test Size = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z19h0hN7_Wg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "491c7417-b4a5-4d6c-f346-50a5bf07de9c"
      },
      "source": [
        "# specifying our features and target variable\n",
        "ffeatt = spam_cl.iloc[:,:47]\n",
        "ttargg = spam.iloc[:,57]\n",
        "\n",
        "\n",
        "# splitting the features and target variables into training and test sets with a test size of 0.4/40% of dataframe\n",
        "feeatt_train, feeatt_test, taargg_train, taargg_test = train_test_split(ffeatt, ttargg, test_size=0.4, random_state=30)\n",
        "\n",
        "print('feeatt train shape:', feeatt_train.shape)\n",
        "print('taargg train shape:', taargg_train.shape)\n",
        "print('feeatt test shape:', feeatt_test.shape)\n",
        "print('taargg test shape:', taargg_test.shape)\n",
        "# feat.head()"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feeatt train shape: (2760, 47)\n",
            "taargg train shape: (2760,)\n",
            "feeatt test shape: (1841, 47)\n",
            "taargg test shape: (1841,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVrSOKdDYotf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scaling the training and test features\n",
        "mmaxscaler = MinMaxScaler()\n",
        "feeatt_train = mmaxscaler.fit_transform(feeatt_train)\n",
        "feeatt_test = mmaxscaler.transform(feeatt_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGYy0Zn4AU_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "4aff3101-e864-463c-8536-70ff50025f0f"
      },
      "source": [
        "# instantiating the gaussian NB classifier\n",
        "gosian = GaussianNB()\n",
        "\n",
        "# fitting the model with training data\n",
        "gosian.fit(feeatt_train, taargg_train)\n",
        "\n",
        "# making predictions with model\n",
        "gosn_pred = gosian.predict(feeatt_test)\n",
        "print('\\n' + '===='*20)\n",
        "\n",
        "# rounding off test set accuracy score to two decimal places\n",
        "np.round(metrics.accuracy_score(taargg_test, gosn_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(taargg_test, gosn_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(taargg_test, gosn_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 384
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 384
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.70      0.81      1136\n",
            "           1       0.66      0.96      0.79       705\n",
            "\n",
            "    accuracy                           0.80      1841\n",
            "   macro avg       0.82      0.83      0.80      1841\n",
            "weighted avg       0.85      0.80      0.80      1841\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[793 343]\n",
            " [ 25 680]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxdzpjmlArGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "d967fd9b-52d9-40fa-dba7-ab4d35ad5886"
      },
      "source": [
        "# using the multinomial model to make predictions\n",
        "multinomio = MultinomialNB()\n",
        "\n",
        "# training the multinomial model with data\n",
        "multinomio.fit(feeatt_train, taargg_train)\n",
        "\n",
        "munomi_pred = multinomio.predict(feeatt_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(taargg_test, munomi_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(taargg_test, munomi_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(taargg_test, munomi_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91      1136\n",
            "           1       0.91      0.77      0.83       705\n",
            "\n",
            "    accuracy                           0.88      1841\n",
            "   macro avg       0.89      0.86      0.87      1841\n",
            "weighted avg       0.88      0.88      0.88      1841\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[1079   57]\n",
            " [ 160  545]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jULzMd0BODg",
        "colab_type": "text"
      },
      "source": [
        "We get the best accuracy accuracy with the multinomial NB when the test size is 0.3 (i.e. ratio of training to test set is 70:30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD7MA6qV7RN3",
        "colab_type": "text"
      },
      "source": [
        "### Optimizing Model by Upsampling and Downsampling to Remove Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFvBmRb8pFgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0077ea81-b67e-470b-d202-78c046415121"
      },
      "source": [
        "# Indicies of each class' observations\n",
        "i_class0 = np.where(targ == 0)[0]\n",
        "i_class1 = np.where(targ == 1)[0]\n",
        "\n",
        "# Number of observations in each class\n",
        "n_class0 = len(i_class0)\n",
        "n_class1 = len(i_class1)\n",
        "\n",
        "print('No of values with entry 0:',n_class0)\n",
        "print('===='*10)\n",
        "print('No of values with entry 1:',n_class1) "
      ],
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of values with entry 0: 2788\n",
            "========================================\n",
            "No of values with entry 1: 1813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGsF4lZvt8Qp",
        "colab_type": "text"
      },
      "source": [
        "Output reveals class1 is shorter than class 0. \n",
        "\n",
        "We will proceed to upsample class 1 and downsample class 0 so that they are fairly even and add up to 4601"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grXQWfVgtt61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "421921b6-cfc8-4401-b14d-9e554200f2de"
      },
      "source": [
        "# For every observation in class 1, randomly sample from class 0 with replacement\n",
        "i_class1_upsampled = np.random.choice(i_class1, size= 2300, replace=True)\n",
        "\n",
        "i_class0_downsampled = np.random.choice(i_class0, size=2301, replace=False)\n",
        "\n",
        "\n",
        "# Join together class 1's upsampled target vector with class 0's target vector\n",
        "concol = np.concatenate((targ[i_class1_upsampled], targ[i_class0_downsampled]))\n",
        "len(concol)"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4601"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mrhs34ZwFTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "96facdc6-1cfb-42a0-e8f4-1ae7878a163f"
      },
      "source": [
        "# creating a copy of the spam dataframe to work on\n",
        "spam_df = spam.copy()\n",
        "\n",
        "# adding the column spam to the copy of the dataframe\n",
        "spam_df['spam'] = pd.Series(concol)\n",
        "spam_df.head()"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      1     2     3    4     5     6  ...     54     55   56    57  58  spam\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.000  3.756   61   278   1     1\n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.048  5.114  101  1028   1     1\n",
              "2  0.06  0.00  0.71  0.0  1.23  0.19  ...  0.010  9.821  485  2259   1     1\n",
              "3  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  3.537   40   191   1     1\n",
              "4  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  3.537   40   191   1     1\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 388
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wvj7ne_wo52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "5cb9758c-51cd-4085-c5fc-e8a0d6331a76"
      },
      "source": [
        "spam_df.drop( axis=1, columns=58, inplace=True)\n",
        "spam_df.head()"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      1     2     3    4     5     6  ...     53     54     55   56    57  spam\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.000  0.000  3.756   61   278     1\n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.180  0.048  5.114  101  1028     1\n",
              "2  0.06  0.00  0.71  0.0  1.23  0.19  ...  0.184  0.010  9.821  485  2259     1\n",
              "3  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191     1\n",
              "4  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191     1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGa5wv_uxPZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e5782517-af2e-4756-9cce-e0c152dc1fd6"
      },
      "source": [
        "# plotting a countplot to show the value counts of entries in the spam column\n",
        "sns.countplot(spam_df.spam)\n",
        "plt.title('Countplot Showing Number of Spam and Non Spam Emails', fontsize=16, color='firebrick')\n",
        "plt.xticks(spam_df.spam.unique(), labels=['Spam', 'Not Spam'])\n",
        "plt.show();"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAEYCAYAAAB4AA4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KNWZ5g_zMhu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "664a6e79-f376-40d2-a915-17b199bc7daf"
      },
      "source": [
        "# defining our independent variables\n",
        "fichas = spam_df.iloc[:,:48]\n",
        "\n",
        "# dropping column 34 to minimize correlation of variables \n",
        "fichas.drop(columns=34, axis=1, inplace=True)\n",
        "\n",
        "# defining the target variable\n",
        "lebo = spam_df.iloc[:,-1]\n",
        "\n",
        "\n",
        "# splitting the data into training and test sets\n",
        "fichas_train, fichas_test, lebo_train, lebo_test = train_test_split(fichas, lebo, test_size=.3, random_state=30)\n",
        "\n",
        "print('fichas train shape:', fichas_train.shape)\n",
        "print('lebo train shape:', lebo_train.shape)\n",
        "print('fichas test shape:', fichas_test.shape)\n",
        "print('lebo test shape:', lebo_test.shape)"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fichas train shape: (3220, 47)\n",
            "lebo train shape: (3220,)\n",
            "fichas test shape: (1381, 47)\n",
            "lebo test shape: (1381,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx9O_aXyZeby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_scaler = MinMaxScaler()\n",
        "fichas_train = m_scaler.fit_transform(fichas_train)\n",
        "fichas_test = m_scaler.transform(fichas_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVt3RtW00sEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "f556f739-5f9f-4590-c4fa-f4351dad0034"
      },
      "source": [
        "# using the multinomial model to make predictions\n",
        "multinom = MultinomialNB()\n",
        "\n",
        "# training the multinomial model with data\n",
        "multinom.fit(fichas_train, lebo_train)\n",
        "\n",
        "mnom_pred = multinom.predict(fichas_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(lebo_test, mnom_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(lebo_test, mnom_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(lebo_test, mnom_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 393
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72.7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 393
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.64      0.71       715\n",
            "           1       0.68      0.82      0.74       666\n",
            "\n",
            "    accuracy                           0.73      1381\n",
            "   macro avg       0.74      0.73      0.73      1381\n",
            "weighted avg       0.74      0.73      0.73      1381\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[459 256]\n",
            " [121 545]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvdn1Q6H2HSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "3325d5b9-8ac8-4e3b-8987-3fd0a9c9135e"
      },
      "source": [
        "gsian = GaussianNB()\n",
        "\n",
        "gsian.fit(fichas_train, lebo_train)\n",
        "\n",
        "gsn_pred = gsian.predict(fichas_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(lebo_test, gsn_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(lebo_test, gsn_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(lebo_test, gsn_pred))\n",
        "print('\\n' + '===='*20)"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70.09"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.59      0.67       715\n",
            "           1       0.65      0.82      0.72       666\n",
            "\n",
            "    accuracy                           0.70      1381\n",
            "   macro avg       0.71      0.70      0.70      1381\n",
            "weighted avg       0.72      0.70      0.70      1381\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[425 290]\n",
            " [123 543]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5WpkZPA205X",
        "colab_type": "text"
      },
      "source": [
        "When we reduce correlated features to improve model performace,the accuracy of the model increases to 85% for multinomial model and 80.67% for the gaussian naives bayes classifier\n",
        "\n",
        "When we balance the values in the target variable , the accuracy of the model decreases to 72.7% for the multinomial naives bayes classifier and 70% for the gaussian naives bayes classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIAh1o6X4dv3",
        "colab_type": "text"
      },
      "source": [
        "## Challenging the Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRhNI5I6aE3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBV0ldqb4hox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "fc06d364-225e-4e57-be92-66c976f01ab3"
      },
      "source": [
        "# using bernoulli naives bayes\n",
        "\n",
        "bern = BernoulliNB(binarize=0.095)\n",
        "\n",
        "bern.fit(ffeatt_train, ttargg_train)\n",
        "\n",
        "bern_pred = bern.predict(ffeatt_test)\n",
        "print('\\n' + '===='*20)\n",
        "np.round(metrics.accuracy_score(ttargg_test, bern_pred) * 100, 2)\n",
        "print('\\n' + '===='*20)\n",
        "print('Classification Report:\\n', metrics.classification_report(ttargg_test, bern_pred))\n",
        "print('\\n' + '===='*20)\n",
        "print('Confusion Matrix:\\n', metrics.confusion_matrix(ttargg_test, bern_pred))\n",
        "print('\\n' + '===='*20)\n",
        "\n",
        "\n"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.095, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 395
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 395
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       863\n",
            "           1       0.80      0.81      0.80       518\n",
            "\n",
            "    accuracy                           0.85      1381\n",
            "   macro avg       0.84      0.84      0.84      1381\n",
            "weighted avg       0.85      0.85      0.85      1381\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Confusion Matrix:\n",
            " [[758 105]\n",
            " [ 99 419]]\n",
            "\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0tTBvafRVnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "bd53cc62-faa4-4a9a-dd0f-f26385d320a9"
      },
      "source": [
        "comp_f = pd.DataFrame({'Target Test': ttargg_test, 'BernNB Pred': bern_pred})\n",
        "print('BernoulliNB Comparison With Test Set:\\n')\n",
        "comp_f.head(10)\n",
        "\n",
        "mnbcomp_f = pd.DataFrame({'Target Test': ttargg_test, 'MultinomialNB Pred': munom_pred})\n",
        "print('\\n\\nMultinomialNB Comparison With Test Set:\\n')\n",
        "mnbcomp_f.head(10)"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BernoulliNB Comparison With Test Set:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target Test</th>\n",
              "      <th>BernNB Pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1762</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2690</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3101</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>945</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3962</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2515</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2092</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Target Test  BernNB Pred\n",
              "1762            1            0\n",
              "2690            0            0\n",
              "326             1            0\n",
              "3101            0            0\n",
              "254             1            1\n",
              "405             1            1\n",
              "945             1            0\n",
              "3962            0            0\n",
              "2515            0            1\n",
              "2092            0            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 396
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "MultinomialNB Comparison With Test Set:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target Test</th>\n",
              "      <th>MultinomialNB Pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1762</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2690</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3101</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>945</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3962</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2515</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2092</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Target Test  MultinomialNB Pred\n",
              "1762            1                   1\n",
              "2690            0                   0\n",
              "326             1                   1\n",
              "3101            0                   0\n",
              "254             1                   1\n",
              "405             1                   1\n",
              "945             1                   0\n",
              "3962            0                   0\n",
              "2515            0                   0\n",
              "2092            0                   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fiIMk01Rxy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "9ecedde3-4218-49e8-edb6-8a3f08b128b4"
      },
      "source": [
        "print('BernoulliNB Comparison With Test Set:\\n')\n",
        "comp_f.describe()\n",
        "\n",
        "print('\\n\\nMultinomialNB Comparison With Test Set:\\n')\n",
        "mnbcomp_f.describe()"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BernoulliNB Comparison With Test Set:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target Test</th>\n",
              "      <th>BernNB Pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1381.000000</td>\n",
              "      <td>1381.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.375091</td>\n",
              "      <td>0.379435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.484322</td>\n",
              "      <td>0.485422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Target Test  BernNB Pred\n",
              "count  1381.000000  1381.000000\n",
              "mean      0.375091     0.379435\n",
              "std       0.484322     0.485422\n",
              "min       0.000000     0.000000\n",
              "25%       0.000000     0.000000\n",
              "50%       0.000000     0.000000\n",
              "75%       1.000000     1.000000\n",
              "max       1.000000     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 397
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "MultinomialNB Comparison With Test Set:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target Test</th>\n",
              "      <th>MultinomialNB Pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1381.000000</td>\n",
              "      <td>1381.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.375091</td>\n",
              "      <td>0.323678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.484322</td>\n",
              "      <td>0.468048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Target Test  MultinomialNB Pred\n",
              "count  1381.000000         1381.000000\n",
              "mean      0.375091            0.323678\n",
              "std       0.484322            0.468048\n",
              "min       0.000000            0.000000\n",
              "25%       0.000000            0.000000\n",
              "50%       0.000000            0.000000\n",
              "75%       1.000000            1.000000\n",
              "max       1.000000            1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ki7EYaTDWhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "0685fdaa-9bc1-4635-ef5f-6c8b4ebf0eca"
      },
      "source": [
        "bern_acc = round(metrics.accuracy_score(ttargg_test, bern_pred) * 100, 2)\n",
        "gasn_acc = round(metrics.accuracy_score(ttargg_test, gasn_pred) * 100, 2)\n",
        "munom_acc = round(metrics.accuracy_score(ttargg_test, munom_pred) * 100, 2)\n",
        "\n",
        "\n",
        "comp_frame = pd.DataFrame({'Model': ['GaussianNB', 'MultinomialNB', 'BernoulliNB'],\n",
        "                          'Acc Score': [gasn_acc, munom_acc, bern_acc]})\n",
        "comp_frame.sort_values('Acc Score', ascending=False, inplace=True)\n",
        "comp_frame"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Acc Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>88.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BernoulliNB</td>\n",
              "      <td>85.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>78.93</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Model  Acc Score\n",
              "1  MultinomialNB      88.49\n",
              "2    BernoulliNB      85.23\n",
              "0     GaussianNB      78.93"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5blEKgzccX-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKc3pHDOcX55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPwa5IgP54zw",
        "colab_type": "text"
      },
      "source": [
        "The multinomial naives bayes classifier exhibits the highest prediction accuracy at 88.49%.\n",
        "\n",
        "Based on accuracy score, the multinomial naives bayes classifier is the best model for predicting whether an email is spam or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq13-D0H8v1a",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsv9-SiZ8y59",
        "colab_type": "text"
      },
      "source": [
        "One can imporove the project by opting to use the multinomial naives bayes classifier.\n",
        "\n",
        "The multinomial NB also boasts the least false positives and therefore, is less likely to categorize important mails as spam\n",
        "\n",
        "A ratio of 70:30(test_size=0.3) for the train and test set ratio yields the highest accuracy\n",
        "\n",
        "When we balance the target variable, the accuracy of the prediction models decrease by apprximately 10%\n",
        "\n",
        "When we remove features with a correlation greater than 0.95, the accuracy of the models (i.e. gaussianNB, bernoulliNB and multinomialNB) increase slightly"
      ]
    }
  ]
}